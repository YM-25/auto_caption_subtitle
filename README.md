<div align="center">
  <h1>AutoCaption Pro ğŸ¥ğŸ“</h1>
  <p><em>Vibe your subtitles like vibing code.</em></p>
  <p><strong>English</strong> | ä¸­æ–‡ (coming soon)</p>
</div>

---

**AutoCaption Pro** is an intelligent, web-based tool designed to automatically generate, translate, and synchronize subtitles for your videos. Powered by OpenAI's **Whisper** model for state-of-the-art speech recognition and **Deep Translator** for multilingual support.

This tool runs fully **locally**. You need a local Python installation and required packages.


## âœ¨ Features

- **ğŸš€ Batch Video Upload**: Upload multiple videos at once and process them in a queue.
- **ğŸ™ï¸ Automatic Transcription**: Converts video speech to text with high accuracy using Whisper.
- **ğŸŒ Smart Translation**:
  - Automatically translates English to **Chinese (Simplified)**.
  - Translates other languages to **English (UK / en-GB)**.
  - If detected Chinese is ambiguous, defaults to **Simplified** for downstream logic.
  - Per-video language selection for customized results (including **Chinese Simplified/Traditional** and **None**).
- **âš¡ Sequential Batch Processing**: Processes videos one by one with individual progress tracking.
- **ğŸ“¥ Multiple Export Formats**:
  - `*.{source}.srt`: Original language subtitles (e.g. `.zh-cn`).
  - `*.{source}__{target}.srt`: Translated subtitles (e.g. `.zh-cn__en-gb`).
  - `*.{source}__{target}.dual.srt`: **Bilingual subtitles** (Target on top, Source on bottom).
- **ğŸ§¾ SRT Translate Mode**: Upload edited SRT files and generate translated + bilingual outputs.
- **ğŸ§¹ History Management**: Cleanly wipes uploaded files and generated transcripts.
- **ğŸ¨ Premium Wide UI**: A modern, 1000px wide horizontal interface for efficient batch work.
- **ğŸ› ï¸ Auto-Dependency Check**: Automatically installs missing Python packages on startup.
- **ğŸ§ª Advanced Settings**: Optional Whisper model selection per batch.
- **ğŸ“ Per-Video Overrides**: You can override model and initial prompt per video.

## ğŸš€ Getting Started

### Prerequisites
- **Python 3.8+**
- **FFmpeg**: Must be installed and added to your system PATH.
- **CUDA (Optional)**: Recommended for faster Whisper transcription (NVIDIA GPU).
- **Upload size limit**: Default max upload is **5 GB** (configurable in `src/config.py`).

### Installation & Run

1. **Clone the repository**:
   ```bash
   git clone https://github.com/yourusername/auto_caption_subtitle.git
   cd auto_caption_subtitle
   ```

2. **Install dependencies**:
  ```bash
  pip install -r requirements.txt
  ```

3. **Run the Application**:
   ```bash
   python app.py
   ```
   *The app will automatically check and install all required dependencies from `requirements.txt` on its first run.*

4. **Open your browser** and navigate to: `http://127.0.0.1:5000`

### Optional configuration

#### Virtual Environment (Recommended)

Create a virtual environment:
```bash
python -m venv .venv
```

Activate it:
- Windows: `.\.venv\Scripts\activate`
- macOS/Linux: `source .venv/bin/activate`

#### Environment Variables (.env)

Copy `.env.example` to `.env` and set variables as needed:

| Variable | Description |
|----------|-------------|
| `FLASK_SECRET_KEY` | Secret key for Flask (recommended in production). |
| `WHISPER_MODEL` | Whisper model: `tiny`, `base`, `small`, `medium`, `large` (default: `base`). |
| `CLEANUP_AFTER_PROCESS` | Set to `1` to delete uploaded video and extracted audio after successful processing. |
| `PORT` | Server port (default: `5000`). |
| `FLASK_DEBUG` | Set to `1` to enable debug mode. |

#### CUDA Acceleration (Optional)

To use CUDA acceleration, install a CUDA-enabled PyTorch build that matches your GPU/driver.
If you choose larger Whisper models (e.g. `medium`/`large`), GPU/CUDA is strongly recommended.
Note: `requirements.txt` installs the default CPU build of PyTorch unless you manually install a CUDA-enabled build.

## ğŸƒ Usage

1. **Upload**: Drag and drop multiple video files onto the upload area.
2. **Configure**: Set individual **Source** and **Target** languages for each video in the horizontal list (including Simplified/Traditional Chinese).
3. **Advanced (Optional)**: Choose a Whisper model and prompt for the batch; per-video overrides are available inside each item.
4. **Process**: Click **Generate All Subtitles**.
5. **Download**: Once a video is done, use the **Get Files** dropdown to download SRT files.
6. **Clear History**: Removes all uploaded videos, extracted audios, and generated transcripts from the server. Use when you want to free disk space or start fresh.

### SRT Translate

1. Switch to the **SRT Translate** tab.
2. Upload one or more `.srt` files.
3. Choose source/target languages and run **Translate SRT Files**.
4. Download the translated and dual subtitles from **Get Files**.

For SRT Translate, if a cue has two lines, the system always treats the **second line** as the source text and regenerates all outputs accordingly.


## ğŸ“‚ Project Structure

```
auto_caption_subtitle/
â”œâ”€â”€ app.py                 # Flask app; dependency check runs only when started here
â”œâ”€â”€ .env.example           # Optional env vars (copy to .env)
â”œâ”€â”€ requirements.txt      # Python dependencies
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py         # Central config: paths, Whisper model, cleanup, secret
â”‚   â”œâ”€â”€ dependency_manager.py  # Check/install deps (invoked at app startup)
â”‚   â”œâ”€â”€ pipeline.py       # Video â†’ audio â†’ transcribe â†’ translate â†’ SRT
â”‚   â”œâ”€â”€ transcriber.py    # Whisper & SRT save helpers
â”‚   â”œâ”€â”€ translator.py     # Segment translation (deep-translator)
â”‚   â””â”€â”€ video_processor.py    # FFmpeg video â†’ audio
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Main UI
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/style.css     # Styles
â”‚   â””â”€â”€ js/script.js      # Upload, NDJSON stream, progress, downloads
â””â”€â”€ data/                 # Auto-created; videos, audios, transcripts (git-ignored)
```

## ğŸ“ License

[MIT License](LICENSE)
